# üåä OceanPhenix IA Souveraine V8

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/docker-compose-2496ED?logo=docker)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/python-3.11+-3776AB?logo=python)](https://www.python.org/)
[![Open WebUI](https://img.shields.io/badge/Open_WebUI-latest-00D9FF)](https://github.com/open-webui/open-webui)

> **Plateforme IA Souveraine compl√®te** avec RAG (Retrieval-Augmented Generation), auto-h√©berg√©e, monitoring 360¬∞ et orchestration intelligente.

## üìã Table des Mati√®res

- [Vue d'Ensemble](#-vue-densemble)
- [Architecture](#Ô∏è-architecture)
- [Fonctionnalit√©s](#-fonctionnalit√©s)
- [Pr√©requis](#-pr√©requis)
- [Installation Rapide](#-installation-rapide)
- [Guides de D√©ploiement](#-guides-de-d√©ploiement)
- [Configuration](#Ô∏è-configuration)
- [Utilisation](#-utilisation)
- [Services Inclus](#Ô∏è-services-inclus)
- [Diagrammes UML](#-diagrammes-uml)
- [API Documentation](#-api-documentation)
- [Maintenance](#-maintenance)
- [Troubleshooting](#-troubleshooting)
- [License](#-license)

## üéØ Vue d'Ensemble

**OceanPhenix IA Souveraine V8** est une plateforme d'intelligence artificielle compl√®te, auto-h√©berg√©e et souveraine, offrant :

- ü§ñ **Interface RAG** avec Open WebUI (chat intelligent avec contexte documentaire)
- üß† **Mod√®les LLM locaux** via Ollama (Mistral, Llama, etc.)
- üìä **Vector Database** Qdrant pour embeddings
- üóÑÔ∏è **Stockage S3** MinIO pour documents
- üìà **Monitoring complet** Grafana + Prometheus
- ‚ö° **Automatisation** n8n workflows
- üê≥ **Infrastructure Docker** compl√®te et orchestr√©e

### üéØ Cas d'Usage

- ‚úÖ Assistance IA conversationnelle avec contexte m√©tier
- ‚úÖ Analyse de documents avec RAG
- ‚úÖ Automatisation de workflows m√©tier
- ‚úÖ Monitoring infrastructure temps r√©el
- ‚úÖ Plateforme IA souveraine pour entreprises

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     FRONTEND LAYER                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ Hub Frontend ‚îÇ  ‚îÇ  Open WebUI  ‚îÇ  ‚îÇ   Grafana    ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (Static)    ‚îÇ  ‚îÇ   (RAG UI)   ‚îÇ  ‚îÇ (Dashboard)  ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                  ‚îÇ                  ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ‚îÇ       API & ORCHESTRATION LAYER     ‚îÇ            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ   Caddy      ‚îÇ  ‚îÇ   FastAPI    ‚îÇ  ‚îÇ  Prometheus  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (Proxy)    ‚îÇ  ‚îÇ  (Backend)   ‚îÇ  ‚îÇ  (Metrics)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              INTELLIGENCE LAYER                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ    Ollama    ‚îÇ‚óÑ‚îÄ‚î§   Qdrant     ‚îÇ  ‚îÇ    MinIO     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (LLM Engine)‚îÇ  ‚îÇ (Vector DB)  ‚îÇ  ‚îÇ (S3 Storage) ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 AUTOMATION LAYER            ‚îÇ              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ     n8n      ‚îÇ  ‚îÇ  Portainer   ‚îÇ  ‚îÇ MinIO Sync   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (Workflows)  ‚îÇ  ‚îÇ(Docker Mgmt) ‚îÇ  ‚îÇ Auto-Indexer ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚ú® Fonctionnalit√©s

### Core Features

- ‚úÖ **RAG (Retrieval-Augmented Generation)** : Chat intelligent avec contexte documentaire
- ‚úÖ **Multi-LLM** : Support Mistral, Llama, GPT-like models via Ollama
- ‚úÖ **Vector Search** : Recherche s√©mantique dans vos documents avec Qdrant
- ‚úÖ **Auto-Indexation** : Upload ‚Üí MinIO ‚Üí Vectorisation ‚Üí RAG (automatique)
- ‚úÖ **S3 Storage** : Stockage documents compatible S3 (MinIO)
- ‚úÖ **API REST** : Backend FastAPI pour int√©grations

### Monitoring & Observability

- üìä **Grafana Dashboards** : Monitoring temps r√©el (CPU, RAM, Disk, Network)
- üìà **Prometheus** : M√©triques et alerting
- üîç **Health Checks** : Surveillance automatique de tous les services
- üìù **Logs centralis√©s** : Agr√©gation et analyse

### Automation & DevOps

- ‚ö° **n8n Workflows** : Automatisation no-code (300+ int√©grations)
- üê≥ **Docker Compose** : Orchestration compl√®te multi-services
- üîÑ **Auto-sync** : Synchronisation MinIO ‚Üî Open WebUI
- üîß **Portainer** : Interface de gestion Docker

### Security & Sovereignty

- üîê **Auto-h√©berg√©** : 100% on-premise, aucune d√©pendance cloud
- üá´üá∑ **Souverain** : Donn√©es en France, conformit√© RGPD
- üîí **Authentification** : Gestion utilisateurs et permissions
- üõ°Ô∏è **Reverse Proxy** : Caddy avec SSL automatique

## üîß Pr√©requis

### Hardware Minimum

| Composant | Local Dev | Production |
|-----------|-----------|------------|
| CPU | 4 cores | 8+ cores |
| RAM | 8 GB | 16+ GB |
| Stockage | 50 GB SSD | 200+ GB SSD |
| GPU | Optionnel | Recommand√© (NVIDIA) |

### Software

- **Docker** : 24.0+ ([Installation](https://docs.docker.com/get-docker/))
- **Docker Compose** : 2.20+ (inclus avec Docker Desktop)
- **Git** : Pour cloner le repository
- **Ports disponibles** : 3000, 3001, 5678, 6333, 8000, 9000, 9001, 9090, 9443, 11434

### Syst√®mes Support√©s

- ‚úÖ Linux (Ubuntu 22.04+, Debian 11+, CentOS 8+)
- ‚úÖ Windows 10/11 avec WSL2
- ‚úÖ macOS 12+ (Intel/Apple Silicon)

## üöÄ Installation Rapide

### Installation en 5 minutes

```bash
# 1. Cloner le repository
git clone https://github.com/stepstev/oceanphenix-IA-souveraine-v8.git
cd oceanphenix-IA-souveraine-v8

# 2. Configurer les variables d'environnement
cp .env.example .env

# 3. D√©marrer la stack compl√®te
docker compose --profile all up -d

# 4. Installer un mod√®le LLM
docker exec v8-ollama ollama pull mistral:latest

# 5. Acc√©der aux interfaces
# Hub Frontend: http://localhost:8080
# Open WebUI: http://localhost:3000
# MinIO: http://localhost:9001
# Grafana: http://localhost:3001
```

### V√©rification

```bash
# Voir les services
docker compose ps

# V√©rifier les logs
docker compose logs -f

# Health check
curl http://localhost:8000/health
```

## üìö Guides de D√©ploiement

### üíª Installation Locale

Guide complet pour d√©veloppement local (Windows, Mac, Linux).

**üìñ Voir** : [docs/INSTALL_LOCAL.md](docs/INSTALL_LOCAL.md)

**√âtapes principales** :
1. Installation Docker Desktop
2. Clone du repository
3. Configuration `.env`
4. Lancement avec `docker compose`
5. Installation mod√®les LLM
6. Test du RAG

---

### üñ•Ô∏è D√©ploiement Serveur Hetzner

Guide pour d√©ploiement production sur VPS Hetzner.

**üìñ Voir** : [docs/deployment/INSTALL_HETZNER.md](docs/deployment/INSTALL_HETZNER.md)

**√âtapes principales** :
1. Cr√©ation serveur Hetzner (Ubuntu 22.04, 8GB+ RAM)
2. Installation Docker
3. Configuration firewall (UFW)
4. Clone et configuration
5. D√©marrage stack
6. Configuration domaine et SSL

**Ressources recommand√©es** :
- **VPS** : CX31 ou sup√©rieur (4 vCPU, 8GB RAM, 160GB SSD)
- **OS** : Ubuntu 22.04 LTS
- **Co√ªt** : ~15‚Ç¨/mois

---

### ‚òÅÔ∏è D√©ploiement Frontend O2Switch

Guide pour h√©bergement frontend statique sur O2Switch.

**üìñ Voir** : [docs/deployment/INSTALL_O2SWITCH.md](docs/deployment/INSTALL_O2SWITCH.md)

**√âtapes principales** :
1. Pr√©paration archive frontend
2. Upload FTP vers O2Switch
3. Configuration `config.prod.js` avec IP Hetzner
4. Activation HTTPS (Let's Encrypt)
5. Test de l'int√©gration

**Avantages O2Switch** :
- H√©bergement mutualis√© fran√ßais
- Domaine + SSL inclus
- Support francophone
- Co√ªt : ~5‚Ç¨/mois

---

### üèóÔ∏è Architecture Compl√®te

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              üë• UTILISATEURS                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚òÅÔ∏è O2SWITCH (Frontend)                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Hub Frontend (HTML/CSS/JS)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - index.html, app.js, config.prod.js             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - HTTPS avec Let's Encrypt                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Domaine: votre-domaine.com                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ API Calls HTTPS
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üñ•Ô∏è HETZNER VPS (Backend)                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  üõ°Ô∏è UFW Firewall (80, 443, 22)                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  üê≥ Docker Compose Stack                    ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ                                              ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Caddy    ‚îÇ  ‚îÇOpen WebUI‚îÇ  ‚îÇ Grafana  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ (Proxy)  ‚îÇ  ‚îÇ  (RAG)   ‚îÇ  ‚îÇ(Monitor) ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ       ‚îÇ             ‚îÇ              ‚îÇ         ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ        Backend Services              ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - FastAPI  - Ollama  - Qdrant      ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  - MinIO    - n8n     - Prometheus  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  IP: xxx.xxx.xxx.xxx                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Configuration

### Profils Docker Compose

```bash
# Core services (proxy, monitoring)
docker compose --profile core up -d

# RAG services (Open WebUI, Ollama, Qdrant, MinIO)
docker compose --profile rag up -d

# All services (tout)
docker compose --profile all up -d
```

### Variables d'Environnement

Fichier `.env` :

```env
# === MINIO S3 STORAGE ===
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=VotreMotDePasseSecurise123!
MINIO_BUCKET_RAG=rag-documents

# === GRAFANA ===
GRAFANA_ADMIN_PASSWORD=VotreMotDePasseGrafana456!

# === OPEN WEBUI ===
OPENWEBUI_API_KEY=

# === BACKEND API ===
API_HOST=0.0.0.0
API_PORT=8000

# === OLLAMA ===
OLLAMA_HOST=http://ollama:11434
```

## üìñ Utilisation

### Interfaces Web

| Service | URL | Identifiants |
|---------|-----|-------------|
| **Hub Frontend** | http://localhost:8080 | Aucun |
| **Open WebUI** | http://localhost:3000 | Signup |
| **MinIO Console** | http://localhost:9001 | admin / [password] |
| **Grafana** | http://localhost:3001 | admin / [password] |
| **n8n** | http://localhost:5678 | Signup |
| **Portainer** | https://localhost:9443 | Signup |
| **Qdrant Dashboard** | http://localhost:6333/dashboard | Aucun |
| **API Swagger** | http://localhost:8000/docs | Aucun |

### Workflow RAG Complet

1. **Upload Document**
   - Aller sur MinIO Console (http://localhost:9001)
   - Login : admin / [votre_password]
   - Upload dans bucket `rag-documents`

2. **Indexation Automatique**
   - Le service `minio-sync` copie le fichier
   - `auto-indexer` d√©tecte et indexe
   - Les embeddings sont g√©n√©r√©s par Ollama
   - Les vecteurs sont stock√©s dans Qdrant

3. **Query RAG**
   - Aller sur Open WebUI (http://localhost:3000)
   - Poser une question sur le document
   - Le LLM r√©pond avec le contexte du document

### Commandes Utiles

```bash
# D√©marrer
docker compose --profile all up -d

# Arr√™ter
docker compose down

# Red√©marrer un service
docker compose restart openwebui

# Voir les logs
docker logs v8-studio -f
docker logs v8-ollama -f
docker logs v8-auto-indexer -f

# Shell dans un conteneur
docker exec -it v8-studio sh

# Lister mod√®les LLM
docker exec v8-ollama ollama list

# Backup MinIO
docker exec v8-minio-sync mc mirror minio/rag-documents /backup
```

## üéõÔ∏è Services Inclus

| Service | Description | Port | Ressources |
|---------|-------------|------|------------|
| **Open WebUI** | Interface RAG chat | 3000 | 2GB RAM |
| **Ollama** | Moteur LLM local | 11434 | 4GB RAM, GPU optionnel |
| **Qdrant** | Base vectorielle | 6333 | 1GB RAM |
| **MinIO** | Stockage S3 | 9000, 9001 | 512MB RAM |
| **FastAPI** | Backend API | 8000 | 512MB RAM |
| **Grafana** | Dashboards | 3001 | 512MB RAM |
| **Prometheus** | M√©triques | 9090 | 512MB RAM |
| **n8n** | Automation | 5678 | 512MB RAM |
| **Portainer** | Docker UI | 9443 | 256MB RAM |
| **Caddy** | Reverse Proxy | 80, 443 | 128MB RAM |

**Total recommand√©** : 16GB RAM, 8 CPU cores, 200GB SSD

## üìä Diagrammes UML

### Diagramme de S√©quence - Upload & Indexation RAG

```mermaid
sequenceDiagram
    participant U as üë§ Utilisateur
    participant M as üóÑÔ∏è MinIO
    participant S as üîÑ MinIO Sync
    participant I as ü§ñ Auto-Indexer
    participant O as üí¨ Open WebUI
    participant L as üß† Ollama
    participant Q as üìä Qdrant

    U->>M: 1. Upload document.pdf
    Note over M: Fichier stock√© dans<br/>bucket rag-documents
    
    M->>S: 2. Event: New file detected
    S->>S: 3. mc mirror --watch
    Note over S: Copie vers volume /docs
    
    S-->>I: 4. File change event
    I->>I: 5. Watchdog d√©tecte fichier
    I->>I: 6. Calculate MD5 hash
    Note over I: V√©rification anti-doublons
    
    I->>O: 7. POST /api/v1/documents
    Note over I,O: Multipart file upload
    
    O->>L: 8. Request embeddings
    Note over L: Mod√®le: nomic-embed-text
    L->>L: 9. Generate vectors
    
    L->>Q: 10. Store vectors in collection
    Note over Q: Vector database<br/>avec m√©tadonn√©es
    
    Q-->>O: 11. Confirmation
    O-->>I: 12. 200 OK - Document indexed
    I->>I: 13. Mark as indexed (MD5 tracked)
    
    Note over U,Q: ‚úÖ Document pr√™t pour RAG queries
```

### Diagramme de S√©quence - RAG Query

```mermaid
sequenceDiagram
    participant U as üë§ Utilisateur
    participant O as üí¨ Open WebUI
    participant Q as üìä Qdrant
    participant L as üß† Ollama

    U->>O: 1. "Question sur mon document ?"
    
    O->>Q: 2. Semantic search query
    Note over Q: Recherche vecteurs<br/>similaires (cosine similarity)
    
    Q->>Q: 3. Find top-K matches
    Q-->>O: 4. Return relevant chunks + metadata
    
    O->>O: 5. Build context prompt
    Note over O: Combine query + chunks<br/>+ system prompt
    
    O->>L: 6. LLM completion request
    Note over L: Mod√®le: mistral:latest<br/>ou llama3.2:3b
    
    L->>L: 7. Generate response with context
    L-->>O: 8. Streaming response
    
    O-->>U: 9. Display answer with sources
    Note over U: R√©ponse contextualis√©e<br/>+ r√©f√©rences documents
```

### Diagramme de Composants

```mermaid
graph TB
    subgraph Frontend["üñ•Ô∏è Frontend Layer"]
        HUB[Hub Frontend<br/>Static HTML/CSS/JS<br/>Port 8080]
        OW[Open WebUI<br/>RAG Interface<br/>Port 3000]
        GR[Grafana<br/>Monitoring Dashboards<br/>Port 3001]
    end

    subgraph API["‚öôÔ∏è API & Orchestration Layer"]
        CADDY[Caddy<br/>Reverse Proxy<br/>Port 80/443]
        FAST[FastAPI<br/>Backend API<br/>Port 8000]
        PROM[Prometheus<br/>Metrics Collector<br/>Port 9090]
    end

    subgraph Intelligence["üß† Intelligence Layer"]
        OLLAMA[Ollama<br/>LLM Engine<br/>Port 11434]
        QDRANT[Qdrant<br/>Vector Database<br/>Port 6333]
        MINIO[MinIO<br/>S3 Storage<br/>Port 9000/9001]
    end

    subgraph Automation["üîÑ Automation Layer"]
        N8N[n8n<br/>Workflows<br/>Port 5678]
        PORT[Portainer<br/>Docker Management<br/>Port 9443]
        SYNC[MinIO Sync<br/>Watch Service]
        AUTO[Auto-Indexer<br/>Document Processor]
    end

    HUB --> CADDY
    OW --> FAST
    GR --> PROM
    FAST --> OLLAMA
    FAST --> QDRANT
    FAST --> MINIO
    OW --> OLLAMA
    OW --> QDRANT
    MINIO --> SYNC
    SYNC --> AUTO
    AUTO --> OW
    OLLAMA --> QDRANT

    style Frontend fill:#e0f7fa
    style API fill:#f3e5f5
    style Intelligence fill:#fff3e0
    style Automation fill:#e8f5e9
```

### Diagramme de D√©ploiement

```mermaid
graph TB
    subgraph Client["üë• Clients / Utilisateurs"]
        BROWSER[üåê Navigateur Web]
        API_CLIENT[üîå API Clients]
    end

    subgraph O2Switch["‚òÅÔ∏è O2Switch - Frontend H√©bergement"]
        STATIC["Hub Frontend - HTTPS"]
    end

    subgraph Internet["üåê Internet"]
        DNS[üîó DNS Records]
    end

    subgraph Hetzner["üñ•Ô∏è Hetzner VPS - Backend"]
        subgraph Firewall["üõ°Ô∏è UFW Firewall"]
            FW_RULES["Ports: 80, 443, 22"]
        end
        
        subgraph Docker["üê≥ Docker Host Ubuntu 22.04"]
            subgraph Compose["Docker Compose Stack"]
                PROXY[Caddy Proxy]
                WEB[Open WebUI]
                API[FastAPI]
                LLM[Ollama]
                VDB[Qdrant]
                S3[MinIO]
                MON[Grafana+Prometheus]
                AUTO_SERVICES["n8n + Portainer + Sync"]
            end
            
            VOLUMES[("Docker Volumes")]
        end
    end

    BROWSER -->|HTTPS| DNS
    API_CLIENT -->|HTTPS| DNS
    DNS -->|Domain Resolution| STATIC
    DNS -->|Domain/IP Resolution| FW_RULES
    
    STATIC -.->|API Calls HTTPS| FW_RULES
    
    FW_RULES --> PROXY
    PROXY --> WEB
    PROXY --> API
    PROXY --> MON
    
    API --> LLM
    API --> VDB
    API --> S3
    WEB --> LLM
    WEB --> VDB
    
    COMPOSE --> VOLUMES
    
    style Client fill:#e3f2fd
    style O2Switch fill:#f3e5f5
    style Hetzner fill:#fff3e0
    style Docker fill:#e8f5e9
```

### Diagramme de Classes - Backend API

```mermaid
classDiagram
    class FastAPI {
        +app: FastAPI
        +router: APIRouter
        +startup_event()
        +shutdown_event()
    }

    class DocumentService {
        +storage: MinIO
        +vectordb: Qdrant
        +llm: Ollama
        +upload_document(file)
        +get_document(id)
        +delete_document(id)
        +list_documents()
    }

    class RAGService {
        +vectordb: Qdrant
        +llm: Ollama
        +embeddings_model: str
        +query(question, k=5)
        +generate_embeddings(text)
        +search_similar(query_vector, k)
        +generate_response(context, question)
    }

    class MinIOClient {
        +endpoint: str
        +access_key: str
        +secret_key: str
        +bucket: str
        +upload_file(file, filename)
        +download_file(filename)
        +delete_file(filename)
        +list_files()
    }

    class QdrantClient {
        +host: str
        +port: int
        +collection: str
        +create_collection()
        +insert_vectors(vectors, metadata)
        +search(query_vector, limit)
        +delete_vector(id)
    }

    class OllamaClient {
        +host: str
        +model: str
        +generate_embeddings(text)
        +generate_completion(prompt)
        +list_models()
        +pull_model(name)
    }

    FastAPI --> DocumentService
    FastAPI --> RAGService
    DocumentService --> MinIOClient
    DocumentService --> QdrantClient
    RAGService --> QdrantClient
    RAGService --> OllamaClient
    DocumentService --> OllamaClient
```

## üìö API Documentation

### Backend API (FastAPI)

**Base URL** : `http://localhost:8000`

**Swagger UI** : http://localhost:8000/docs  
**ReDoc** : http://localhost:8000/redoc

#### Endpoints principaux

```bash
# Health check
GET /health

# Documents
GET  /api/documents         # Liste documents
POST /api/documents         # Upload document
GET  /api/documents/{id}    # Get document
DELETE /api/documents/{id}  # Supprimer document

# RAG
POST /api/rag/query         # RAG query
GET  /api/rag/collections   # Liste collections

# Models
GET /api/models             # Liste mod√®les LLM
POST /api/models/pull       # Pull nouveau mod√®le
```

#### Exemples cURL

```bash
# Health check
curl http://localhost:8000/health

# Upload document
curl -X POST http://localhost:8000/api/documents \
  -F "file=@document.pdf" \
  -H "Content-Type: multipart/form-data"

# RAG query
curl -X POST http://localhost:8000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Quelle est la politique de remboursement ?",
    "k": 5
  }'

# List models
curl http://localhost:8000/api/models
```

### Open WebUI API

**Base URL** : `http://localhost:3000`

**Documentation** : https://docs.openwebui.com/api

Pour g√©n√©rer une API Key :
1. Open WebUI ‚Üí Settings
2. Account ‚Üí API Keys
3. Create new key
4. Copier dans `.env` : `OPENWEBUI_API_KEY=sk-...`

## üîß Maintenance

### Backup

```bash
# Backup volumes Docker
docker run --rm \
  -v oceanphenix-v8_minio_data:/data \
  -v $(pwd)/backups:/backup \
  alpine tar czf /backup/minio-$(date +%Y%m%d).tar.gz /data

# Backup Qdrant
docker exec v8-qdrant tar czf /tmp/qdrant-backup.tar.gz /qdrant/storage
docker cp v8-qdrant:/tmp/qdrant-backup.tar.gz ./backups/

# Backup configuration
tar czf config-backup-$(date +%Y%m%d).tar.gz .env docker-compose.yml
```

### Mise √† Jour

```bash
# Pull derni√®res images
docker compose pull

# Red√©marrer services
docker compose --profile all up -d

# V√©rifier
docker compose ps
docker compose logs -f
```

### Monitoring

Dashboards Grafana disponibles :
- **Platform Health** : CPU, RAM, Disk, Network
- **Docker Stats** : Containers, images, volumes
- **Ollama Performance** : Requ√™tes LLM, latence
- **MinIO Metrics** : Stockage, bande passante

## üêõ Troubleshooting

### Open WebUI erreur 500

```bash
# Voir logs
docker logs v8-studio --tail 100

# Red√©marrer
docker compose restart openwebui

# Si probl√®me persiste
docker compose down
docker volume rm oceanphenix-v8_openwebui_data
docker compose --profile all up -d
```

### Ollama mod√®le non trouv√©

```bash
# Lister mod√®les
docker exec v8-ollama ollama list

# R√©installer
docker exec v8-ollama ollama pull mistral:latest

# Test connexion
curl http://localhost:11434/api/tags
```

### MinIO bucket non cr√©√©

```bash
# Logs sync
docker logs v8-minio-sync

# Cr√©er manuellement
docker exec v8-minio-sync mc mb minio/rag-documents

# V√©rifier
docker exec v8-minio-sync mc ls minio/
```

### Ports d√©j√† utilis√©s

```bash
# Windows
netstat -ano | findstr :3000

# Linux/Mac
lsof -i :3000

# Changer port dans docker-compose.yml
ports:
  - "3010:3000"  # Utiliser 3010 au lieu de 3000
```

## üìÑ License

Ce projet est sous licence MIT. Voir [LICENSE](LICENSE) pour plus de d√©tails.

## üîó Liens Utiles

- **Repository GitHub** : https://github.com/stepstev/oceanphenix-IA-souveraine-v8
- **Documentation** : [docs/](docs/)
- **Issues** : https://github.com/stepstev/oceanphenix-IA-souveraine-v8/issues

---

**D√©velopp√© avec ‚ù§Ô∏è par l'√©quipe OceanPhenix**

*Version 8.0.0 - D√©cembre 2025*
